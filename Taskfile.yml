# yaml-language-server: $schema=https://taskfile.dev/schema.json

version: "3"

dotenv: ["secrets/.env"]

vars:
  PROJECT_ID: '{{.PROJECT_ID | default "gen-lang-client-0800253336"}}'
  REGION: '{{.REGION | default "asia-northeast1"}}'

  # Resource Configurations from JSON
  BE_CPU:
    {
      sh: 'python3 -c ''import json; print(json.load(open("config/resources.json"))["backend"]["cpu"])''',
    }
  BE_MEM:
    {
      sh: 'python3 -c ''import json; print(json.load(open("config/resources.json"))["backend"]["memory"])''',
    }
  BE_STG_CPU:
    {
      sh: 'python3 -c ''import json; print(json.load(open("config/resources.json"))["backend_staging"]["cpu"])''',
    }
  BE_STG_MEM:
    {
      sh: 'python3 -c ''import json; print(json.load(open("config/resources.json"))["backend_staging"]["memory"])''',
    }

  INF_CPU:
    {
      sh: 'python3 -c ''import json; print(json.load(open("config/resources.json"))["inference"]["cpu"])''',
    }
  INF_MEM:
    {
      sh: 'python3 -c ''import json; print(json.load(open("config/resources.json"))["inference"]["memory"])''',
    }
  INF_STG_CPU:
    {
      sh: 'python3 -c ''import json; print(json.load(open("config/resources.json"))["inference_staging"]["cpu"])''',
    }
  INF_STG_MEM:
    {
      sh: 'python3 -c ''import json; print(json.load(open("config/resources.json"))["inference_staging"]["memory"])''',
    }
  INF_STG_WORKERS:
    {
      sh: 'python3 -c ''import json; print(json.load(open("config/resources.json"))["inference_staging"].get("batch_parallel_workers", 2))''',
    }

  INF_WORKERS:
    {
      sh: 'python3 -c ''import json; print(json.load(open("config/resources.json"))["inference"].get("batch_parallel_workers", 2))''',
    }

  BUILD_MACHINE:
    {
      sh: 'python3 -c ''import json; print(json.load(open("config/resources.json"))["build"]["machine_type"])''',
    }

  # Staging Deployment Variables
  STG_SECRET_ENV: "GEMINI_API_KEY=GEMINI_API_KEY:latest,FIREBASE_API_KEY=FIREBASE_API_KEY:latest,FIREBASE_AUTH_DOMAIN=FIREBASE_AUTH_DOMAIN:latest,FIREBASE_PROJECT_ID=FIREBASE_PROJECT_ID:latest,FIREBASE_STORAGE_BUCKET=FIREBASE_STORAGE_BUCKET:latest,FIREBASE_MESSAGING_SENDER_ID=FIREBASE_MESSAGING_SENDER_ID:latest,FIREBASE_APP_ID=FIREBASE_APP_ID:latest,FIREBASE_MEASUREMENT_ID=FIREBASE_MEASUREMENT_ID:latest"

  STG_BE_ENV_VARS: 'AI_PROVIDER={{.AI_PROVIDER | default "gemini"}},OCR_MODEL={{.OCR_MODEL | default "gemini-1.5-flash"}},LOG_LEVEL={{.LOG_LEVEL | default "INFO"}},ACCESS_LOG_LEVEL={{.ACCESS_LOG_LEVEL | default "INFO"}},INFERENCE_SERVICE_TIMEOUT={{.INFERENCE_SERVICE_TIMEOUT | default "200"}},SKIP_INFERENCE_SERVICE_WARMUP={{.SKIP_INFERENCE_SERVICE_WARMUP | default "false"}},STORAGE_TYPE={{.STORAGE_TYPE | default "gcs"}},GCS_BUCKET_NAME={{.GCS_BUCKET_NAME | default "paperterrace-papers"}}'

  STG_INF_ENV_VARS: 'LOG_LEVEL={{.LOG_LEVEL | default "INFO"}},DEV_MODE=false,SKIP_MODEL_LOADING=false,LOCAL_MODEL_PATH={{.LOCAL_MODEL_PATH | default "/app/models/m2m100_ct2"}},TRANSLATION_BEAM_SIZE={{.TRANSLATION_BEAM_SIZE | default "5"}},TRANSLATION_REPETITION_PENALTY={{.TRANSLATION_REPETITION_PENALTY | default "1.4"}},TRANSLATION_NO_REPEAT_NGRAM_SIZE={{.TRANSLATION_NO_REPEAT_NGRAM_SIZE | default "3"}},LAYOUT_THRESHOLD={{.LAYOUT_THRESHOLD | default 0.9}},BATCH_PARALLEL_WORKERS={{.INF_STG_WORKERS}}'

  # Staging Resource Configurations
  BE_STG_MIN_INSTANCES: '{{.BE_STG_MIN_INSTANCES | default "0"}}'
  BE_STG_MAX_INSTANCES: '{{.BE_STG_MAX_INSTANCES | default "20"}}'
  BE_STG_CONCURRENCY: '{{.BE_STG_CONCURRENCY | default "80"}}'
  BE_STG_TIMEOUT: '{{.BE_STG_TIMEOUT | default "300"}}'

  INF_STG_MIN_INSTANCES: '{{.INF_STG_MIN_INSTANCES | default "0"}}'
  INF_STG_MAX_INSTANCES: '{{.INF_STG_MAX_INSTANCES | default "10"}}'
  INF_STG_CONCURRENCY: '{{.INF_STG_CONCURRENCY | default "10"}}'
  INF_STG_TIMEOUT: '{{.INF_STG_TIMEOUT | default "300"}}'

tasks:
  # ============================================================================
  # Development Tasks
  # ============================================================================

  default:
    desc: "Show available tasks"
    cmds:
      - task --list
    silent: true

  setup:
    desc: "Setup development environment"
    cmds:
      - echo "üîß Setting up development environment..."
      - task: redis
      - echo "‚úÖ Development environment ready!"

  redis:
    desc: "Start Redis container for local development"
    cmds:
      - docker run -d --name paper-terrace-redis -p 6379:6379 redis:latest || docker start paper-terrace-redis

  run:
    desc: "Run backend server with hot reload"
    cmds:
      - mkdir -p logs
      - PYTHONUNBUFFERED=1 uv run --directory backend env PYTHONPATH=.:.. uvicorn app.main:app --reload --host 0.0.0.0 --port 8000 | tee -a logs/local.log

  dev:
    desc: "Run frontend dev server"
    cmds:
      - npm run dev
    dir: frontend

  dev:full:
    desc: "Run both backend and frontend in parallel"
    deps: [redis]
    cmds:
      - echo "üöÄ Starting full development environment..."
      - |
        # Start backend in background
        PYTHONUNBUFFERED=1 uv run --directory backend env PYTHONPATH=.:.. uvicorn app.main:app --reload --host 0.0.0.0 --port 8000 &
        BACKEND_PID=$!

        # Start frontend in background  
        cd frontend && npm run dev &
        FRONTEND_PID=$!

        echo "Backend PID: $BACKEND_PID"
        echo "Frontend PID: $FRONTEND_PID"
        echo "Press Ctrl+C to stop both services"

        # Wait for interrupt
        trap "kill $BACKEND_PID $FRONTEND_PID 2>/dev/null; exit" INT
        wait

  build:
    desc: "Build frontend for production"
    cmds:
      - npm run build
    dir: frontend

  test:
    desc: "Run backend tests"
    cmds:
      - uv run --directory backend pytest

  lint:
    desc: "Run linting and formatting"
    cmds:
      - echo "üîç Running backend linting..."
      - uv run --directory backend ruff check --fix .
      - echo "üîç Running frontend linting..."
      - cd frontend && npm run lint

  clean:
    desc: "Clean cache and temporary files"
    cmds:
      - echo "üßπ Cleaning cache..."
      - rm -rf backend/.ruff_cache backend/__pycache__ backend/app/__pycache__
      - rm -rf frontend/node_modules/.cache frontend/dist
      - sqlite3 ocr_reader.db "DELETE FROM ocr_reader;" 2>/dev/null || true
      - rm -rf backend/app/static/paper_images/* 2>/dev/null || true
      - rm -rf logs/*.log
      - echo "‚úÖ Cache cleared!"

  # ============================================================================
  # Production Tasks
  # ============================================================================

  deploy:
    desc: "Deploy to production"
    cmds:
      - echo "üöÄ Deploying to production..."
      - ./scripts/deployment/deploy.sh

  deploy:fast:
    desc: "Fast deploy (skip infrastructure checks)"
    cmds:
      - ./scripts/deployment/deploy.sh --skip-infra

  # ============================================================================
  # Database Tasks
  # ============================================================================

  db:start:
    desc: "Start Cloud SQL instance"
    cmds:
      - echo "üîÑ Starting Cloud SQL instance..."
      - gcloud sql instances patch paperterrace-db --activation-policy=ALWAYS
      - task: db:wait

  db:stop:
    desc: "Stop Cloud SQL instance (save cost)"
    cmds:
      - echo "‚èπÔ∏è Stopping Cloud SQL instance..."
      - gcloud sql instances patch paperterrace-db --activation-policy=NEVER

  db:wait:
    desc: "Wait for Cloud SQL to be ready"
    cmds:
      - |
        echo "‚è≥ Waiting for Cloud SQL to be RUNNABLE..."
        for i in {1..6}; do
          STATUS=$(gcloud sql instances describe paperterrace-db --format="value(state)")
          echo "Current state: $STATUS"
          if [ "$STATUS" = "RUNNABLE" ]; then
            echo "‚úÖ Cloud SQL is ready"
            exit 0
          fi
          sleep 30
        done
        echo "‚ùå Cloud SQL did not become RUNNABLE"
        exit 1

  db:migrate:
    desc: "Run database migrations"
    cmds:
      - echo "üîÑ Running database migrations..."
      - uv run --directory backend alembic upgrade head

  # ============================================================================
  # Staging Environment Tasks
  # ============================================================================

  staging:deploy:servicea:
    desc: "Deploy backend to staging environment"
    cmds:
      - echo "üöÄ Deploying backend to staging..."
      - gcloud auth configure-docker {{.REGION}}-docker.pkg.dev --quiet
      - docker build --platform linux/amd64 -f backend/Dockerfile -t {{.REGION}}-docker.pkg.dev/{{.PROJECT_ID}}/paperterrace/app:staging .
      - docker push {{.REGION}}-docker.pkg.dev/{{.PROJECT_ID}}/paperterrace/app:staging
      - |
        SERVICEB_URL=$(gcloud run services describe paperterrace-inference-staging --region {{.REGION}} --format="value(status.url)" 2>/dev/null || echo "")
        if [ -z "$SERVICEB_URL" ]; then
          echo "‚ö†Ô∏è ServiceB not found. Deploy inference service first with: task staging:deploy:serviceb"
          SERVICEB_URL="https://paperterrace-inference-staging-placeholder.run.app"
        fi

        gcloud run deploy paperterrace-staging \
          --image {{.REGION}}-docker.pkg.dev/{{.PROJECT_ID}}/paperterrace/app:staging \
          --region {{.REGION}} \
          --allow-unauthenticated \
          --memory {{.BE_STG_MEM}} \
          --cpu {{.BE_STG_CPU}} \
          --min-instances {{.BE_STG_MIN_INSTANCES}} \
          --max-instances {{.BE_STG_MAX_INSTANCES}} \
          --concurrency {{.BE_STG_CONCURRENCY}} \
          --timeout {{.BE_STG_TIMEOUT}} \
          --set-secrets "{{.STG_SECRET_ENV}}" \
          --set-env-vars "{{.STG_BE_ENV_VARS}},INFERENCE_SERVICE_URL=$SERVICEB_URL"
      - echo "‚úÖ Backend deployed to staging!"
      - task: staging:urls

  staging:deploy:serviceb:
    desc: "Deploy inference service to staging"
    cmds:
      - echo "üî® Building and deploying inference service..."
      - gcloud auth configure-docker {{.REGION}}-docker.pkg.dev --quiet
      - docker build --platform linux/amd64 -f inference-service/Dockerfile -t {{.REGION}}-docker.pkg.dev/{{.PROJECT_ID}}/paperterrace/inference:staging .
      - docker push {{.REGION}}-docker.pkg.dev/{{.PROJECT_ID}}/paperterrace/inference:staging
      - |
        gcloud run deploy paperterrace-inference-staging \
          --image {{.REGION}}-docker.pkg.dev/{{.PROJECT_ID}}/paperterrace/inference:staging \
          --region {{.REGION}} \
          --allow-unauthenticated \
          --memory {{.INF_STG_MEM}} \
          --cpu {{.INF_STG_CPU}} \
          --min-instances {{.INF_STG_MIN_INSTANCES}} \
          --max-instances {{.INF_STG_MAX_INSTANCES}} \
          --concurrency {{.INF_STG_CONCURRENCY}} \
          --timeout {{.INF_STG_TIMEOUT}} \
          --set-env-vars "{{.STG_INF_ENV_VARS}}"
      - echo "‚úÖ Inference service deployed to staging!"
      - task: staging:urls

  staging:deploy:
    desc: "Deploy both backend and inference to staging"
    cmds:
      - echo "üöÄ Deploying all services to staging..."
      - task: staging:deploy:serviceb
      - echo "‚è≥ Waiting 10 seconds for inference service to be ready..."
      - sleep 10
      - task: staging:deploy:servicea
      - echo "üéâ All services deployed to staging!"

  staging:test:
    desc: "Run comprehensive staging tests"
    cmds:
      - echo "üß™ Running staging tests..."
      - task: staging:health
      - task: staging:test:translation
      - echo "‚úÖ All staging tests passed!"

  staging:test:translation:
    desc: "Test translation functionality"
    cmds:
      - echo "üî§ Testing translation..."
      - |
        SERVICEB_URL=$(gcloud run services describe paperterrace-inference-staging --region {{.REGION}} --format="value(status.url)" 2>/dev/null)
        if [ -z "$SERVICEB_URL" ]; then
          echo "‚ùå Inference service not found. Deploy first with: task staging:deploy:serviceb"
          exit 1
        fi

        echo "Testing translation endpoint: $SERVICEB_URL/api/v1/translate"

        RESPONSE=$(curl -s -X POST "$SERVICEB_URL/api/v1/translate" \
          -H "Content-Type: application/json" \
          -d '{"text": "Hello world",  "target_lang": "ja"}' \
          -w "\n%{http_code}")

        HTTP_CODE=$(echo "$RESPONSE" | tail -n1)
        BODY=$(echo "$RESPONSE" | head -n-1)

        echo "HTTP Status: $HTTP_CODE"
        echo "Response: $BODY"

        if [ "$HTTP_CODE" = "200" ]; then
          SUCCESS=$(echo "$BODY" | grep -o '"success":[^,}]*' | cut -d':' -f2)
          if [ "$SUCCESS" = "true" ]; then
            TRANSLATION=$(echo "$BODY" | grep -o '"translation":"[^"]*"' | cut -d'"' -f4)
            echo "‚úÖ Translation successful: Hello world ‚Üí $TRANSLATION"
          else
            echo "‚ùå Translation returned success=false"
            exit 1
          fi
        else
          echo "‚ùå Translation test failed with HTTP $HTTP_CODE"
          exit 1
        fi

  staging:test:upload:
    desc: "Test PDF upload with test.pdf"
    cmds:
      - |
        STAGING_URL=$(gcloud run services describe paperterrace-staging --region {{.REGION}} --format="value(status.url)" 2>/dev/null)
        if [ -z "$STAGING_URL" ]; then
          echo "‚ùå Staging service not found. Deploy first with: task staging:deploy"
          exit 1
        fi

        echo "üìÑ Testing PDF upload to: $STAGING_URL"

        # Check if test.pdf exists
        if [ ! -f "frontend/public/test.pdf" ]; then
          echo "‚ùå test.pdf not found in frontend/public/"
          exit 1
        fi

        # Test health endpoint first
        echo "üîç Testing health endpoint..."
        curl -f "$STAGING_URL/api/health" || (echo "‚ùå Health check failed" && exit 1)

        # Test PDF upload with correct endpoint
        echo "üì§ Uploading test.pdf..."
        RESPONSE=$(curl -s -w "%{http_code}" -o /tmp/upload_response.json -X POST "$STAGING_URL/api/analyze-pdf-json" \
          -F "file=@frontend/public/test.pdf" \
          -F "session_id=test-session-$(date +%s)" \
          -F "lang=ja")

        echo "HTTP Status: $RESPONSE"
        echo "Response:"
        cat /tmp/upload_response.json

        # Check if upload was successful (HTTP 200)
        if [ "$RESPONSE" = "200" ]; then
          TASK_ID=$(cat /tmp/upload_response.json | grep -o '"task_id":"[^"]*"' | cut -d'"' -f4)
          if [ -n "$TASK_ID" ]; then
            echo "‚úÖ PDF upload successful! Task ID: $TASK_ID"
            echo "üîÑ Stream URL: $STAGING_URL/api/stream/$TASK_ID"
          else
            echo "‚ö†Ô∏è Upload response missing task_id"
          fi
        else
          echo "‚ùå PDF upload failed with HTTP $RESPONSE"
          exit 1
        fi

  staging:health:
    desc: "Check staging services health"
    cmds:
      - echo "üîç Checking staging services health..."
      - |
        # Check Backend
        BACKEND_URL=$(gcloud run services describe paperterrace-staging --region {{.REGION}} --format="value(status.url)" 2>/dev/null)
        if [ -n "$BACKEND_URL" ]; then
          echo "Backend: $BACKEND_URL"
          if curl -f -s "$BACKEND_URL/api/health" > /dev/null 2>&1; then
            echo "‚úÖ Backend healthy"
          else
            echo "‚ùå Backend unhealthy"
          fi
        else
          echo "‚ö†Ô∏è Backend not deployed"
        fi

        # Check Inference Service
        INFERENCE_URL=$(gcloud run services describe paperterrace-inference-staging --region {{.REGION}} --format="value(status.url)" 2>/dev/null)
        if [ -n "$INFERENCE_URL" ]; then
          echo "Inference: $INFERENCE_URL"
          if curl -f -s "$INFERENCE_URL/health" > /dev/null 2>&1; then
            echo "‚úÖ Inference service healthy"
          else
            echo "‚ùå Inference service unhealthy"
          fi
        else
          echo "‚ö†Ô∏è Inference service not deployed"
        fi

  staging:logs:
    desc: "Show combined staging logs"
    cmds:
      - echo "üìã Staging combined logs (last 50 entries):"
      - gcloud run services logs read paperterrace-staging --limit=50 --region {{.REGION}} --format="table(receiveTimestamp.date(tz='Asia/Tokyo'):label=TIME, severity, textPayload, jsonPayload.event:label=MESSAGE)"

  staging:logs:servicea:
    desc: "Show backend logs (Service A)"
    cmds:
      - echo "üìã Backend logs (last 50 entries) -> logs/servicea.log"
      - mkdir -p logs
      - gcloud logging read 'resource.type="cloud_run_revision" AND resource.labels.service_name="paperterrace-staging"' --limit=50 --format="table(timestamp.date(tz='Asia/Tokyo'):label=TIME, severity, textPayload, jsonPayload.event:label=MESSAGE)" | tee -a logs/servicea.log

  staging:logs:serviceb:
    desc: "Show inference service logs (Service B)"
    cmds:
      - echo "üìã Inference service logs (last 50 entries) -> logs/serviceb.log"
      - mkdir -p logs
      - gcloud logging read 'resource.type="cloud_run_revision" AND resource.labels.service_name="paperterrace-inference-staging"' --limit=50 --format="table(timestamp.date(tz='Asia/Tokyo'):label=TIME, severity, textPayload, jsonPayload.event:label=MESSAGE)" | tee -a logs/serviceb.log

  staging:logs:tail:servicea:
    desc: "Tail backend logs in real-time"
    cmds:
      - echo "üìã Tailing backend logs (Ctrl+C to stop)..."
      - gcloud logging tail 'resource.type="cloud_run_revision" AND resource.labels.service_name="paperterrace-staging"' --format="table(timestamp.date(tz='Asia/Tokyo'):label=TIME, severity, textPayload, jsonPayload.event:label=MESSAGE)"

  staging:logs:tail:serviceb:
    desc: "Tail inference service logs in real-time"
    cmds:
      - echo "üìã Tailing inference service logs (Ctrl+C to stop)..."
      - gcloud logging tail 'resource.type="cloud_run_revision" AND resource.labels.service_name="paperterrace-inference-staging"' --format="table(timestamp.date(tz='Asia/Tokyo'):label=TIME, severity, textPayload, jsonPayload.event:label=MESSAGE)"

  staging:logs:errors:
    desc: "Show only error logs from staging"
    cmds:
      - echo "üî¥ Error logs from staging:"
      - gcloud logging read 'resource.type="cloud_run_revision"\
        AND (resource.labels.service_name="paperterrace-staging"\
        OR resource.labels.service_name="paperterrace-inference-staging")\
        AND severity>=ERROR' \
        --limit=20 --format="table(timestamp.date(tz='Asia/Tokyo'):label=TIME, \
        resource.labels.service_name:label=SERVICE, severity, textPayload, \
        jsonPayload.event:label=MESSAGE)" --order=asc

  staging:deploy:debug:
    desc: "Deploy staging services with DEBUG log level"
    cmds:
      - echo "‚öôÔ∏è Setting LOG_LEVEL=DEBUG for staging services..."
      - gcloud run services update paperterrace-staging --region {{.REGION}} --update-env-vars LOG_LEVEL=DEBUG,ACCESS_LOG_LEVEL=DEBUG
      - gcloud run services update paperterrace-inference-staging --region {{.REGION}} --update-env-vars LOG_LEVEL=DEBUG

  staging:urls:
    desc: "Show staging service URLs"
    cmds:
      - echo "üîó Staging Service URLs:"
      - |
        BACKEND_URL=$(gcloud run services describe paperterrace-staging --region {{.REGION}} --format="value(status.url)" 2>/dev/null)
        INFERENCE_URL=$(gcloud run services describe paperterrace-inference-staging --region {{.REGION}} --format="value(status.url)" 2>/dev/null)

        if [ -n "$BACKEND_URL" ]; then
          echo "Backend: $BACKEND_URL"
        else
          echo "Backend: Not deployed"
        fi

        if [ -n "$INFERENCE_URL" ]; then
          echo "Inference: $INFERENCE_URL"
        else
          echo "Inference: Not deployed"
        fi

  staging:stop:
    desc: "Stop staging services"
    cmds:
      - echo "üõë Stopping staging services..."
      - gcloud run services delete paperterrace-staging --region {{.REGION}} --quiet 2>/dev/null || echo "Backend already stopped"
      - gcloud run services delete paperterrace-inference-staging --region {{.REGION}} --quiet 2>/dev/null || echo "Inference service already stopped"
      - echo "‚úÖ Staging services stopped!"

  # ============================================================================
  # Monitoring & Logs
  # ============================================================================

  logs:prod:
    desc: "Show production logs"
    cmds:
      - echo "üìã Production combined logs (last 100 entries):"
      - gcloud run services logs read paperterrace --limit=100 --region {{.REGION}} --format="table(receiveTimestamp.date(tz='Asia/Tokyo'):label=TIME, severity, textPayload, jsonPayload.event:label=MESSAGE)"

  logs:prod:tail:
    desc: "Tail production logs"
    cmds:
      - echo "üìã Tailing production logs (Ctrl+C to stop)..."
      - gcloud run services logs tail paperterrace --region {{.REGION}} --format="table(receiveTimestamp.date(tz='Asia/Tokyo'):label=TIME, severity, textPayload, jsonPayload.event:label=MESSAGE)"

  logs:errors:
    desc: "Show error logs"
    cmds:
      - gcloud logging read 'resource.type="cloud_run_revision" AND severity>=ERROR' --limit=50 --format="table(timestamp,severity,resource.labels.service_name,textPayload)" 2>/dev/null || echo "No error logs found"

  # ============================================================================
  # Infrastructure Tasks
  # ============================================================================

  infra:init:production:
    desc: "Initialize Terraform for production"
    cmds:
      - echo "üîß Initializing Terraform for production..."
      - unset GOOGLE_APPLICATION_CREDENTIALS && cd infrastructure/environments/production && terraform init

  infra:init:staging:
    desc: "Initialize Terraform for staging"
    cmds:
      - echo "üîß Initializing Terraform for staging..."
      - unset GOOGLE_APPLICATION_CREDENTIALS && cd infrastructure/environments/staging && terraform init

  infra:import:production:
    desc: "Import existing GCP resources into Terraform state (production)"
    cmds:
      - echo "üì• Importing existing resources to Terraform..."
      - unset GOOGLE_APPLICATION_CREDENTIALS && cd infrastructure/environments/production && terraform import -var="project_id={{.PROJECT_ID}}" -var="region={{.REGION}}" -var="gemini_api_key=${GEMINI_API_KEY}" -var="db_password=${DB_PASSWORD}" -var="image_url={{.REGION}}-docker.pkg.dev/{{.PROJECT_ID}}/paperterrace/app:latest" module.artifact_registry.google_artifact_registry_repository.main projects/{{.PROJECT_ID}}/locations/{{.REGION}}/repositories/paperterrace || echo "‚ö†Ô∏è Already imported or not found"
      - unset GOOGLE_APPLICATION_CREDENTIALS && cd infrastructure/environments/production && terraform import -var="project_id={{.PROJECT_ID}}" -var="region={{.REGION}}" -var="gemini_api_key=${GEMINI_API_KEY}" -var="db_password=${DB_PASSWORD}" -var="image_url={{.REGION}}-docker.pkg.dev/{{.PROJECT_ID}}/paperterrace/app:latest" module.iam.google_service_account.app_sa projects/{{.PROJECT_ID}}/serviceAccounts/paperterrace-sa@{{.PROJECT_ID}}.iam.gserviceaccount.com || echo "‚ö†Ô∏è Already imported or not found"
      - unset GOOGLE_APPLICATION_CREDENTIALS && cd infrastructure/environments/production && terraform import -var="project_id={{.PROJECT_ID}}" -var="region={{.REGION}}" -var="gemini_api_key=${GEMINI_API_KEY}" -var="db_password=${DB_PASSWORD}" -var="image_url={{.REGION}}-docker.pkg.dev/{{.PROJECT_ID}}/paperterrace/app:latest" module.networking.google_compute_network.main projects/{{.PROJECT_ID}}/global/networks/paperterrace-vpc || echo "‚ö†Ô∏è Already imported or not found"
      - echo "‚úÖ Import complete!"

  infra:plan:production:
    desc: "Plan Terraform changes for production"
    cmds:
      - echo "üìã Planning Terraform changes for production..."
      - unset GOOGLE_APPLICATION_CREDENTIALS && cd infrastructure/environments/production && terraform plan -var="project_id={{.PROJECT_ID}}" -var="region={{.REGION}}" -var="gemini_api_key=${GEMINI_API_KEY}" -var="db_password=${DB_PASSWORD}" -var="image_url={{.REGION}}-docker.pkg.dev/{{.PROJECT_ID}}/paperterrace/app:latest"

  infra:apply:production:
    desc: "Apply Terraform changes for production"
    cmds:
      - echo "üöÄ Applying Terraform changes for production..."
      - unset GOOGLE_APPLICATION_CREDENTIALS && cd infrastructure/environments/production && terraform apply -var="project_id={{.PROJECT_ID}}" -var="region={{.REGION}}" -var="gemini_api_key=${GEMINI_API_KEY}" -var="db_password=${DB_PASSWORD}" -var="image_url={{.REGION}}-docker.pkg.dev/{{.PROJECT_ID}}/paperterrace/app:latest"

  infra:plan:staging:
    desc: "Plan Terraform changes for staging"
    cmds:
      - echo "üìã Planning Terraform changes for staging..."
      - unset GOOGLE_APPLICATION_CREDENTIALS && cd infrastructure/environments/staging && terraform plan -var="project_id={{.PROJECT_ID}}" -var="region={{.REGION}}" -var="image_url={{.REGION}}-docker.pkg.dev/{{.PROJECT_ID}}/paperterrace/app:staging"

  infra:apply:staging:
    desc: "Apply Terraform changes for staging"
    cmds:
      - echo "üöÄ Applying Terraform changes for staging..."
      - unset GOOGLE_APPLICATION_CREDENTIALS && cd infrastructure/environments/staging && terraform apply -var="project_id={{.PROJECT_ID}}" -var="region={{.REGION}}" -var="image_url={{.REGION}}-docker.pkg.dev/{{.PROJECT_ID}}/paperterrace/app:staging"

  infra:destroy:staging:
    desc: "Destroy staging infrastructure"
    cmds:
      - echo "‚ö†Ô∏è Destroying staging infrastructure..."
      - unset GOOGLE_APPLICATION_CREDENTIALS && cd infrastructure/environments/staging && terraform destroy -var="project_id={{.PROJECT_ID}}" -var="region={{.REGION}}" -var="image_url={{.REGION}}-docker.pkg.dev/{{.PROJECT_ID}}/paperterrace/app:staging"

  # ============================================================================
  # Utility Tasks
  # ============================================================================

  iam:add:
    desc: "Add public access to production service"
    cmds:
      - gcloud run services add-iam-policy-binding paperterrace --member="allUsers" --role="roles/run.invoker"

  iam:remove:
    desc: "Remove public access from production service"
    cmds:
      - gcloud run services remove-iam-policy-binding paperterrace --member="allUsers" --role="roles/run.invoker"

  cleanup:
    desc: "Clean up unused Docker images and containers"
    cmds:
      - echo "üßπ Cleaning up Docker resources..."
      - docker system prune -f
      - echo "‚úÖ Docker cleanup complete!"
